{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayakju/llm-practice/blob/main/cc_statement_analyzer_using_gpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet google-api-python-client pdfplumber PyPDF2 openai python-dotenv"
      ],
      "metadata": {
        "id": "3F15c1Fbatyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import base64\n",
        "import pdfplumber\n",
        "import PyPDF2\n",
        "from google.colab import files, userdata\n",
        "from google.oauth2.credentials import Credentials\n",
        "from googleapiclient.discovery import build\n",
        "from openai import OpenAI\n",
        "\n",
        "# === Upload OAuth files ===\n",
        "print(\"Please upload both 'token.json' and 'credentials.json'\")\n",
        "uploaded = files.upload()  # This will prompt file upload\n",
        "\n",
        "# Save uploaded files to disk\n",
        "for fn in uploaded.keys():\n",
        "    with open(fn, 'wb') as f:\n",
        "        f.write(uploaded[fn])\n",
        "\n",
        "# Confirm upload\n",
        "if not os.path.exists(\"token.json\") or not os.path.exists(\"credentials.json\"):\n",
        "    raise FileNotFoundError(\"Both 'token.json' and 'credentials.json' must be uploaded.\")\n",
        "else:\n",
        "    print(\"âœ… Files uploaded successfully.\")\n",
        "\n",
        "# CONFIG\n",
        "SCOPES = ['https://www.googleapis.com/auth/gmail.readonly']\n",
        "CREDENTIALS_PATH = 'token.json'\n",
        "PDF_PASSWORD = input(\"Enter your PDF password: \")"
      ],
      "metadata": {
        "id": "VHDTQN-catyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Gmail API\n",
        "creds = Credentials.from_authorized_user_file(CREDENTIALS_PATH, SCOPES)\n",
        "gmail_service = build('gmail', 'v1', credentials=creds)"
      ],
      "metadata": {
        "id": "FRWEZ1iSatyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_emails(query):\n",
        "    results = gmail_service.users().messages().list(userId='me', q=query).execute()\n",
        "    return results.get('messages', [])\n",
        "\n",
        "def get_email_attachments(msg_id):\n",
        "    msg = gmail_service.users().messages().get(userId='me', id=msg_id, format='full').execute()\n",
        "    attachments = []\n",
        "    def extract(parts):\n",
        "        for part in parts:\n",
        "            filename = part.get(\"filename\", \"\")\n",
        "            body = part.get(\"body\", {})\n",
        "            if filename.endswith(\".PDF\") or filename.endswith(\".pdf\"):\n",
        "                if \"attachmentId\" in body:\n",
        "                    att_id = body[\"attachmentId\"]\n",
        "                    attachment = gmail_service.users().messages().attachments().get(userId='me', messageId=msg_id, id=att_id).execute()\n",
        "                    data = base64.urlsafe_b64decode(attachment['data'])\n",
        "                    attachments.append((filename, data))\n",
        "            if \"parts\" in part:\n",
        "                extract(part['parts'])\n",
        "    payload = msg.get(\"payload\", {})\n",
        "    if \"parts\" in payload:\n",
        "        extract(payload['parts'])\n",
        "    return attachments"
      ],
      "metadata": {
        "id": "qX_BNXo7atyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from io import BytesIO\n",
        "\n",
        "def extract_text_from_pdf(data):\n",
        "    with open(\"temp.pdf\", \"wb\") as f:\n",
        "        f.write(data)\n",
        "    try:\n",
        "        with open(\"temp.pdf\", \"rb\") as f:\n",
        "            reader = PyPDF2.PdfReader(f)\n",
        "            if reader.is_encrypted:\n",
        "                reader.decrypt(PDF_PASSWORD)\n",
        "            text = \"\"\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text() or \"\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(\"PDF decryption or extraction failed:\", e)\n",
        "        return \"\"\n",
        "\n",
        "def extract_summary_page(pdf_bytes):\n",
        "    with pdfplumber.open(BytesIO(pdf_bytes)) as pdf:\n",
        "        # Assuming first page contains total spend\n",
        "        return pdf.pages[0].extract_text()\n",
        "\n",
        "def extract_summary_page_from_protected_pdf(pdf_bytes):\n",
        "    # First decrypt with PyPDF2\n",
        "    decrypted_stream = BytesIO()\n",
        "    with BytesIO(pdf_bytes) as input_stream:\n",
        "        reader = PyPDF2.PdfReader(input_stream)\n",
        "        if reader.is_encrypted:\n",
        "            try:\n",
        "                reader.decrypt(PDF_PASSWORD)\n",
        "            except:\n",
        "                raise ValueError(\"Incorrect PDF password.\")\n",
        "        writer = PyPDF2.PdfWriter()\n",
        "        writer.add_page(reader.pages[0])\n",
        "        writer.write(decrypted_stream)\n",
        "\n",
        "    # Now extract text from decrypted page using pdfplumber\n",
        "    decrypted_stream.seek(0)\n",
        "    with pdfplumber.open(decrypted_stream) as pdf:\n",
        "        return pdf.pages[0].extract_text()"
      ],
      "metadata": {
        "id": "t2_I5zUhatyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_with_gpt4(text):\n",
        "    client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": (\n",
        "                    \"You are a financial assistant that extracts numeric data from anonymized credit card statement texts.\"\n",
        "                    \" Do not retain or refer to personal data.\"\n",
        "                )\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": (\n",
        "                    \"Extract only the *total spend amount* from the following credit card statement text.\\n\"\n",
        "                    \"Return only the number with no extra text, no currency symbol, and no formatting.\\n\\n\"\n",
        "                    f\"{text}\"\n",
        "                )\n",
        "            }\n",
        "        ],\n",
        "        temperature=0,\n",
        "        max_tokens=50\n",
        "    )\n",
        "    return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "WqI_MnLP_TDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interpret_credit_card_statement(text):\n",
        "    print(\"Summarizing extracted text with GPT-4...\")\n",
        "    short_text = text[:4000]  # GPT input limit\n",
        "    summary = summarize_with_gpt4(short_text)\n",
        "    return summary"
      ],
      "metadata": {
        "id": "VNdCLeZGuQ6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Change this to match your filename or date format in PDF\n",
        "def extract_date_from_filename(filename):\n",
        "    # Example filename: 4375XXXXXXXXXX76_09-07-2025.PDF\n",
        "    try:\n",
        "        date_str = filename.split('_')[-1].replace('.PDF', '')\n",
        "        return datetime.strptime(date_str, \"%d-%m-%Y\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not parse date from {filename}: {e}\")\n",
        "        return None\n",
        "\n",
        "# GPT-4 total spend extraction\n",
        "def extract_total_spend(text):\n",
        "    try:\n",
        "        total_str = summarize_with_gpt4(text)\n",
        "        return float(total_str)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to extract total spend: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "\n",
        "# Define anniversary start date\n",
        "anniversary_start = datetime(2023, 11, 9)  # 09-Nov-2023\n",
        "today = datetime.today()\n",
        "\n",
        "# Build anniversary buckets\n",
        "buckets = []\n",
        "current_start = anniversary_start\n",
        "while current_start < today:\n",
        "    next_start = current_start.replace(year=current_start.year + 1)\n",
        "    is_ongoing = today < next_start\n",
        "    buckets.append({\n",
        "        \"start\": current_start,\n",
        "        \"end\": next_start - timedelta(days=1),\n",
        "        \"spend\": 0.0,\n",
        "        \"status\": \"ongoing\" if is_ongoing else \"complete\"\n",
        "    })\n",
        "    current_start = next_start\n",
        "\n",
        "# Main processing\n",
        "query = 'subject:\"Your HDFC Bank - Infinia Credit Card Statement\" has:attachment'\n",
        "# query = 'subject:\"ICICI Bank Credit Card Statement for the period\" has:attachment'\n",
        "messages = search_emails(query)\n",
        "print(f\"Found {len(messages)} email(s) matching the query.\")\n",
        "\n",
        "for msg in messages:\n",
        "    print(f\"Processing email ID: {msg['id']}\")\n",
        "    attachments = get_email_attachments(msg['id'])\n",
        "    for fname, data in attachments:\n",
        "        print(f\"  - {fname}\")\n",
        "        statement_date = extract_date_from_filename(fname)\n",
        "        if not statement_date:\n",
        "            print(\"    Skipping: Invalid or missing date in filename.\")\n",
        "            continue\n",
        "\n",
        "        # Match to correct bucket\n",
        "        matched_bucket = None\n",
        "        for b in buckets:\n",
        "            if b[\"start\"] <= statement_date <= b[\"end\"]:\n",
        "                matched_bucket = b\n",
        "                break\n",
        "        if not matched_bucket:\n",
        "            print(\"    Skipping: Statement outside all buckets.\")\n",
        "            continue\n",
        "\n",
        "        # Extract and accumulate spend\n",
        "        text = extract_summary_page_from_protected_pdf(data)\n",
        "        if text:\n",
        "            spend = extract_total_spend(text)\n",
        "            print(f\"    Total Spend: â‚¹{spend}\")\n",
        "            matched_bucket[\"spend\"] += spend\n",
        "\n",
        "# Final summary output\n",
        "print(\"\\nðŸ“Š HDFC Infinia Spend Summary by Anniversary Year:\")\n",
        "for i, b in enumerate(buckets, 1):\n",
        "    status = \"ðŸŸ¢ Ongoing\" if b[\"status\"] == \"ongoing\" else \"âœ… Completed\"\n",
        "    print(f\"  {status} | Bucket {i}: {b['start'].strftime('%d-%b-%Y')} to {b['end'].strftime('%d-%b-%Y')} â†’ â‚¹{b['spend']:.2f}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7aeFk95aatyz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}